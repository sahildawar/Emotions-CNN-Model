{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzF0FfX4yP9KhuIoSJoTSo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahildawar/Emotions-CNN-Model/blob/main/Emotions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfcbM9kSiw_B"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QlAIuYIHQPoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "w9q9FcHvQUJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ananthu017/emotion-detection-fer\n",
        "!unzip -q emotion-detection-fer.zip"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KXnUE3eqR2oQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "metadata": {
        "id": "xo6ILq2z9cXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 48\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"train\",\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"train\",\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical',\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "fmJFsmArTgrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(image, label):\n",
        "    image = tf.cast(image / 255.0, tf.float32)\n",
        "    return image, label\n",
        "\n",
        "train_ds = train_ds.map(normalize)\n",
        "val_ds = val_ds.map(normalize)\n"
      ],
      "metadata": {
        "id": "ZYyHqQ5cVyVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(7, activation='softmax')  # 7 emotion classes\n",
        "])"
      ],
      "metadata": {
        "id": "UPahG4KnV8lE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "R6UuyFOoWL34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=30\n",
        "                    )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0VIItRcMWemu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the test dataset (like you did for train and validation)\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'test',  # Path to your test dataset directory\n",
        "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    label_mode='categorical'  # or 'binary' depending on your problem\n",
        ")\n",
        "\n",
        "# Apply the same preprocessing to the test dataset (normalization)\n",
        "test_ds = test_ds.map(lambda x, y: (x / 255.0, y))\n"
      ],
      "metadata": {
        "id": "ALrImE0_ZTed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_ds)\n",
        "print(f\"Predictions for the test dataset: {predictions}\")"
      ],
      "metadata": {
        "id": "EyDSf7p4ZX1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_ds)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "g6Obme2Wbxec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming class_names is defined based on the dataset (adjust to your dataset)\n",
        "class_names = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']  # Update with your actual class names\n",
        "\n",
        "# Fetch a batch of images and labels from test_ds\n",
        "for images_batch, labels_batch in test_ds.take(1):\n",
        "\n",
        "    # Get the first image and label from the batch\n",
        "    first_image = images_batch[0].numpy().astype('uint8')\n",
        "    first_label = labels_batch[0].numpy()\n",
        "\n",
        "    # If labels are one-hot encoded, use np.argmax to get the index\n",
        "    if first_label.ndim > 0:  # One-hot encoded label\n",
        "        first_label = np.argmax(first_label)\n",
        "\n",
        "\n",
        "\n",
        "    # Print the actual label for the first image\n",
        "    print(\"Actual label:\", class_names[first_label])\n",
        "\n",
        "    # Get predictions for the entire batch\n",
        "    batch_prediction = model.predict(images_batch)\n",
        "\n",
        "    # Get the predicted label for the first image\n",
        "    predicted_label = class_names[np.argmax(batch_prediction[0])]\n",
        "\n",
        "    # Print the predicted label for the first image\n",
        "    print(\"Predicted label:\", predicted_label)\n"
      ],
      "metadata": {
        "id": "L2cC4Le5a8EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "img_path = '/content/WIN_20250413_15_23_55_Pro.jpg'  # <-- Update this\n",
        "target_size = (48, 48)  # Replace with your IMAGE_SIZE\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = image.load_img(img_path, target_size=target_size)\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = img_array / 255.0  # normalize\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Make it (1, height, width, channels)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(img_array)\n",
        "predicted_label = class_names[np.argmax(pred)]\n",
        "\n",
        "# Show image and prediction\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Predicted: {predicted_label}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-scymegEjnlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract accuracy and loss from history object\n",
        "history_dict = history.history\n",
        "train_acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "train_loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs = range(1, len(train_acc) + 1)\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training & validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "23PfnChTdOcr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}